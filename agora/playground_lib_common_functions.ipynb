{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lib.common.affine.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "def transform3(m, v):\n",
    "    '''\n",
    "    args :\n",
    "        m : np.ndarray, shape = (4, 4) or (B, 4, 4)\n",
    "        v : np.ndarray, shape = (3,) or (B, 3)\n",
    "    return :\n",
    "        np.ndarray, shape=(3,)\n",
    "    '''\n",
    "    return transform_vec3(m, v) + m[..., :3, 3]\n",
    "\n",
    "def transform_vec3(m, v):\n",
    "    if m.ndim == 2:\n",
    "        return (v.reshape(-1, 3) @ m[:3, :3].T).reshape(v.shape)\n",
    "    else:\n",
    "        return (m[..., :3, :3] @ v[..., None]).squeeze(-1)\n",
    "\n",
    "def normalized(v: np.ndarray, axis: int = -1, eps: float = 5.43e-20) -> np.ndarray:\n",
    "    d = np.maximum(eps, (v * v).sum(axis=axis, keepdims=True) ** 0.5)\n",
    "    return v / d\n",
    "\n",
    "def skew_matrix(v: np.ndarray) -> np.ndarray:\n",
    "    res = np.array(\n",
    "        [[0, -v[2], v[1]], [v[2], 0, -v[0]], [-v[1], v[0], 0]], dtype=v.dtype\n",
    "    )\n",
    "    return res\n",
    "\n",
    "def from_two_vectors(a_orig: np.ndarray, b_orig: np.ndarray) -> np.ndarray:\n",
    "    a = normalized(a_orig)\n",
    "    b = normalized(b_orig)\n",
    "    v = np.cross(a, b)\n",
    "    s = np.linalg.norm(v)\n",
    "    c = np.dot(a, b)\n",
    "    v_mat = skew_matrix(v)\n",
    "\n",
    "    rot = np.eye(3, 3) + v_mat + np.matmul(v_mat, v_mat) * (1 - c) / (max(s * s, 1e-15))\n",
    "\n",
    "    return rot\n",
    "\n",
    "\n",
    "def make_look_at_matrix(\n",
    "    orig_world_to_eye: np.ndarray,\n",
    "    center: np.ndarray,\n",
    "    camera_angle: float = 0,\n",
    ") -> np.ndarray:\n",
    "    center_local = transform3(orig_world_to_eye, center)\n",
    "    z_dir_local = center_local / np.linalg.norm(center_local)\n",
    "    delta_r_local = from_two_vectors(\n",
    "        np.array([0, 0, 1], dtype=center.dtype), z_dir_local\n",
    "    )\n",
    "    orig_eye_to_world = np.linalg.inv(orig_world_to_eye)\n",
    "\n",
    "    new_eye_to_world = orig_eye_to_world.copy()\n",
    "    new_eye_to_world[0:3, 0:3] = orig_eye_to_world[0:3, 0:3] @ delta_r_local\n",
    "\n",
    "    # Locally rotate the z axis to align with the camera angle\n",
    "    z_local_rot = Rotation.from_euler(\"z\", camera_angle, degrees=True).as_matrix()\n",
    "    new_eye_to_world[0:3, 0:3] = new_eye_to_world[0:3, 0:3] @ z_local_rot\n",
    "\n",
    "    return np.linalg.inv(new_eye_to_world)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play with affine.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotated_v: [1 1 1]\n",
      "transformed_v: [3 4 5]\n"
     ]
    }
   ],
   "source": [
    "m = np.array([\n",
    "    [1, 0, 0, 2],\n",
    "    [0, 1, 0, 3],\n",
    "    [0, 0, 1, 4],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "\n",
    "v = np.array([1, 1, 1])\n",
    "\n",
    "rotated_v = transform_vec3(m, v)\n",
    "transformed_v = transform3(m, v)\n",
    "\n",
    "print(\"rotated_v:\", rotated_v)  # Expected: [1, 1, 1]\n",
    "print(\"transformed_v:\", transformed_v)  # Expected: [3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3, 1)\n",
      "\n",
      "(3,)\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "m = np.array([\n",
    "    [1, 0, 0, 2],\n",
    "    [0, 1, 0, 3],\n",
    "    [0, 0, 1, 4],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "\n",
    "print(m[:3, 3].shape)\n",
    "print(m[:3, 3:].shape)\n",
    "print()\n",
    "\n",
    "print(m[..., :3, 3].shape)\n",
    "print(m[..., :3, 3:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "\n",
      "[[3 4 5]\n",
      " [3 4 5]\n",
      " [3 4 5]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = np.array([\n",
    "    [1, 0, 0, 2],\n",
    "    [0, 1, 0, 3],\n",
    "    [0, 0, 1, 4],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "\n",
    "v = np.array([1, 1, 1])\n",
    "v = np.array([\n",
    "    [1],\n",
    "    [1],\n",
    "    [1]\n",
    "])\n",
    "\n",
    "# Applying transform_vec3\n",
    "rotated_v = transform_vec3(m, v)  # This would just apply rotation (and scaling if any)\n",
    "print(rotated_v)\n",
    "print()\n",
    "\n",
    "# Applying transform3\n",
    "transformed_v = transform3(m, v)  # This applies rotation and then adds translation\n",
    "print(transformed_v)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lib.common.camera.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import abc\n",
    "import json\n",
    "import math\n",
    "from typing import NamedTuple, Sequence, Tuple, Type\n",
    "from typing_extensions import Protocol, runtime_checkable\n",
    "\n",
    "\n",
    "class CameraProjection(Protocol):\n",
    "    \"\"\"\n",
    "    Defines a projection from a 3D `xyz` direction or point to 2D.\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    @abc.abstractmethod\n",
    "    def project(cls, v):\n",
    "        \"\"\"\n",
    "        Project a 3d vector in eye space down to 2d.\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "    @classmethod\n",
    "    @abc.abstractmethod\n",
    "    def unproject(cls, p):\n",
    "        \"\"\"\n",
    "        Unproject a 2d point to a unit-length vector in eye space.\n",
    "\n",
    "        `project(unproject(p)) == p`\n",
    "        `unproject(project(v)) == v / |v|`\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "@runtime_checkable\n",
    "class DistortionModel(Protocol):\n",
    "    @abc.abstractmethod\n",
    "    def evaluate(self: Sequence[float], p: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        p: ndarray[..., 2]\n",
    "            Array of 2D points, of arbitrary batch shape.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        q: ndarray[..., 2]\n",
    "            Distorted points with same shape as input\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "class PerspectiveProjection(CameraProjection):\n",
    "    @staticmethod\n",
    "    def project(v):\n",
    "        # map to [x/z, y/z]\n",
    "        assert v.shape[-1] == 3\n",
    "        return v[..., :2] / v[..., 2, None]\n",
    "\n",
    "    @staticmethod\n",
    "    def unproject(p):\n",
    "        # map to [u,v,1] and renormalize\n",
    "        assert p.shape[-1] == 2\n",
    "        x, y = np.moveaxis(p, -1, 0)\n",
    "        v = np.stack((x, y, np.ones(shape=x.shape, dtype=x.dtype)), axis=-1)\n",
    "        v = affine.normalized(v, axis=-1)\n",
    "        return v\n",
    "\n",
    "\n",
    "class ArctanProjection(CameraProjection):\n",
    "    @staticmethod\n",
    "    def project(p, eps: float = 2.0**-128):\n",
    "        assert p.shape[-1] == 3\n",
    "        x, y, z = np.moveaxis(p, -1, 0)\n",
    "        r = np.sqrt(x * x + y * y)\n",
    "        s = np.arctan2(r, z) / np.maximum(r, eps)\n",
    "        return np.stack((x * s, y * s), axis=-1)\n",
    "\n",
    "    @staticmethod\n",
    "    def unproject(uv):\n",
    "        assert uv.shape[-1] == 2\n",
    "        u, v = np.moveaxis(uv, -1, 0)\n",
    "        r = np.sqrt(u * u + v * v)\n",
    "        c = np.cos(r)\n",
    "        s = np.sinc(r / np.pi)\n",
    "        return np.stack([u * s, v * s, c], axis=-1)\n",
    "\n",
    "\n",
    "class NoDistortion(NamedTuple):\n",
    "    \"\"\"\n",
    "    A trivial distortion model that does not distort the incoming rays.\n",
    "    \"\"\"\n",
    "\n",
    "    def evaluate(self, p: np.ndarray) -> np.ndarray:\n",
    "        return p\n",
    "\n",
    "\n",
    "class Fisheye62CameraModel(NamedTuple):\n",
    "    \"\"\"\n",
    "    Fisheye62CameraModel model, with 6 radial and 2 tangential coeffs.\n",
    "    \"\"\"\n",
    "\n",
    "    k1: float\n",
    "    k2: float\n",
    "    k3: float\n",
    "    k4: float\n",
    "    p1: float\n",
    "    p2: float\n",
    "    k5: float\n",
    "    k6: float\n",
    "\n",
    "    def evaluate(self: Sequence[float], p: np.ndarray) -> np.ndarray:\n",
    "        k1, k2, k3, k4, p1, p2, k5, k6 = self\n",
    "        # radial component\n",
    "        r2 = (p * p).sum(axis=-1, keepdims=True)\n",
    "        r2 = np.clip(r2, -np.pi**2, np.pi**2)\n",
    "        r4 = r2 * r2\n",
    "        r6 = r2 * r4\n",
    "        r8 = r4 * r4\n",
    "        r10 = r4 * r6\n",
    "        r12 = r6 * r6\n",
    "        radial = 1 + k1 * r2 + k2 * r4 + k3 * r6 + k4 * r8 + k5 * r10 + k6 * r12\n",
    "        uv = p * radial\n",
    "\n",
    "        # tangential component\n",
    "        x, y = uv[..., 0], uv[..., 1]\n",
    "        x2 = x * x\n",
    "        y2 = y * y\n",
    "        xy = x * y\n",
    "        r2 = x2 + y2\n",
    "        x += 2 * p2 * xy + p1 * (r2 + 2 * x2)\n",
    "        y += 2 * p1 * xy + p2 * (r2 + 2 * y2)\n",
    "        return np.stack((x, y), axis=-1)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# API Conventions and naming\n",
    "#\n",
    "# Points have the xyz or uv components in the last axis, and may have\n",
    "# arbitrary batch shapes. ([...,2] for 2d and [...,3] for 3d).\n",
    "#\n",
    "# v\n",
    "#    3D xyz position in eye space, usually unit-length.\n",
    "# p\n",
    "#    projected uv coordinates: `p = project(v)`\n",
    "# q\n",
    "#    distorted uv coordinates: `q = distort(p)`\n",
    "# w\n",
    "#    window coordinates: `q = q * f + [cx, cy]`\n",
    "#\n",
    "# A trailing underscore (e.g. `p_`, `q_`) should be read as \"hat\", and\n",
    "# generally indicates an approximation to another value.\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class CameraModel(CameraProjection, abc.ABC):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    width, height : int\n",
    "        Size of the sensor window\n",
    "\n",
    "    f : float or tuple(float, float)\n",
    "        Focal length\n",
    "\n",
    "    c : tuple(float, float)\n",
    "        Optical center in window coordinates\n",
    "\n",
    "    distort_coeffs\n",
    "        Forward distortion coefficients (eye -> window).\n",
    "\n",
    "        If this is an instance of DistortionModel, it will be used as-is\n",
    "        (even if it's a different polynomial than this camera model\n",
    "        would normally use.) If it's a simple tuple or array, it will\n",
    "        used as coefficients for `self.distortion_model`.\n",
    "\n",
    "    camera_to_world_xf : np.ndarray\n",
    "        Camera's position and orientation in world space, represented as\n",
    "        a 3x4 or 4x4 matrix.\n",
    "\n",
    "        The matrix be a rigid transform (only rotation and translation).\n",
    "\n",
    "        You can change a camera's camera_to_world_xf after construction by\n",
    "        assigning to or modifying this matrix.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    Most attributes are the same as constructor parameters.\n",
    "\n",
    "    distortion_model\n",
    "        Class attribute giving the distortion model for new instances.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    width: int\n",
    "    height: int\n",
    "\n",
    "    f: Tuple[float, float]\n",
    "    c: Tuple[float, float]\n",
    "\n",
    "    camera_to_world_xf: np.ndarray\n",
    "\n",
    "    distortion_model: Type[DistortionModel]\n",
    "    distort: DistortionModel\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        width,\n",
    "        height,\n",
    "        f,\n",
    "        c,\n",
    "        distort_coeffs,\n",
    "        camera_to_world_xf=None,\n",
    "    ):  # pylint: disable=super-init-not-called (see issue 4790 on pylint github)\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "\n",
    "        # f can be either a scalar or (fx,fy) pair. We only fit scalars,\n",
    "        # but may load (fx, fy) from a stored file.\n",
    "        self.f = tuple(np.broadcast_to(f, 2))\n",
    "        self.c = tuple(c)\n",
    "\n",
    "        if camera_to_world_xf is None:\n",
    "            self.camera_to_world_xf = np.eye(4)\n",
    "        else:\n",
    "            self.camera_to_world_xf = camera_to_world_xf\n",
    "\n",
    "        if isinstance(distort_coeffs, DistortionModel):\n",
    "            self.distort = distort_coeffs\n",
    "        else:\n",
    "            self.distort = self.distortion_model(*distort_coeffs)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f\"{type(self).__name__}({self.width}x{self.height}, f={self.f} c={self.c}\"\n",
    "        )\n",
    "\n",
    "    def copy(self, camera_to_world_xf=None):\n",
    "        \"\"\"Return a copy of this camera\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        camera_to_world_xf : 4x4 np.ndarray\n",
    "            Optional new camera_to_world_xf for the new camera model.\n",
    "            Default is to copy this camera's camera_to_world_xf.\n",
    "        \"\"\"\n",
    "        return self.crop(0, 0, self.width, self.height, camera_to_world_xf=camera_to_world_xf)\n",
    "\n",
    "    def world_to_eye(self, v):\n",
    "        \"\"\"\n",
    "        Apply camera camera_to_world_xf to points `v` to get eye coords\n",
    "        \"\"\"\n",
    "        return transform_vec3(self.camera_to_world_xf.T, v - self.camera_to_world_xf[:3, 3])\n",
    "\n",
    "    def eye_to_world(self, v):\n",
    "        \"\"\"\n",
    "        Apply inverse camera camera_to_world_xf to eye points `v` to get world coords\n",
    "        \"\"\"\n",
    "        return transform3(self.camera_to_world_xf, v)\n",
    "\n",
    "    def eye_to_window(self, v):\n",
    "        \"\"\"Project eye coordinates to 2d window coordinates\"\"\"\n",
    "        p = self.project(v)\n",
    "        q = self.distort.evaluate(p)\n",
    "        return q * self.f + self.c\n",
    "\n",
    "    def window_to_eye(self, w):\n",
    "        \"\"\"Unproject 2d window coordinates to unit-length 3D eye coordinates\"\"\"\n",
    "        q = (np.asarray(w) - self.c) / self.f\n",
    "        assert isinstance(\n",
    "            self.distort, NoDistortion\n",
    "        ), \"Only unprojection for NoDistortion camera is supported\"\n",
    "        return self.unproject(q)\n",
    "\n",
    "    def crop(\n",
    "        self,\n",
    "        src_x,\n",
    "        src_y,\n",
    "        target_width,\n",
    "        target_height,\n",
    "        scale=1,\n",
    "        camera_to_world_xf=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Return intrinsics for a crop of the sensor image.\n",
    "\n",
    "        No scaling is applied; this just returns the model for a sub-\n",
    "        array of image data. (Or for a larger array, if (x,y)<=0 and\n",
    "        (width, height) > (self.width, self.height).\n",
    "\n",
    "        To do both cropping and scaling, use :meth:`subrect`\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x, y, width, height\n",
    "            Location and size in this camera's window coordinates\n",
    "        \"\"\"\n",
    "        return type(self)(\n",
    "            target_width,\n",
    "            target_height,\n",
    "            np.asarray(self.f) * scale,\n",
    "            (np.array(self.c) - (src_x, src_y) + 0.5) * scale - 0.5,\n",
    "            self.distort,\n",
    "            self.camera_to_world_xf if camera_to_world_xf is None else camera_to_world_xf,\n",
    "        )\n",
    "\n",
    "\n",
    "# Camera models\n",
    "# =============\n",
    "\n",
    "\n",
    "class PinholePlaneCameraModel(PerspectiveProjection, CameraModel):\n",
    "    distortion_model = NoDistortion\n",
    "\n",
    "    def uv_to_window_matrix(self):\n",
    "        \"\"\"Return the 3x3 intrinsics matrix\"\"\"\n",
    "        return np.array(\n",
    "            [[self.f[0], 0, self.c[0]], [0, self.f[1], self.c[1]], [0, 0, 1]]\n",
    "        )\n",
    "\n",
    "\n",
    "class Fisheye62CameraModel(ArctanProjection, CameraModel):\n",
    "    distortion_model = Fisheye62CameraModel\n",
    "\n",
    "\n",
    "def read_camera_from_json(js):\n",
    "    if isinstance(js, str):\n",
    "        js = json.loads(js)\n",
    "    js = js.get(\"Camera\", js)\n",
    "\n",
    "    width = js[\"ImageSizeX\"]\n",
    "    height = js[\"ImageSizeY\"]\n",
    "    model = js[\"DistortionModel\"]\n",
    "    fx = js[\"fx\"]\n",
    "    fy = js[\"fy\"]\n",
    "    cx = js[\"cx\"]\n",
    "    cy = js[\"cy\"]\n",
    "\n",
    "    if model == \"PinholePlane\":\n",
    "        cls = PinholePlaneCameraModel\n",
    "    elif model == \"FishEye62\":\n",
    "        cls = Fisheye62CameraModel\n",
    "\n",
    "    distort_params = cls.distortion_model._fields\n",
    "    coeffs = [js[name] for name in distort_params]\n",
    "\n",
    "    return cls(width, height, (fx, fy), (cx, cy), coeffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lib.common.crop.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def gen_intrinsics_from_bounding_pts(\n",
    "    pts_eye: np.ndarray, image_w: int, image_h: int, min_focal: float = 5\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    pts_ndc = pts_eye[..., 0:2] / pts_eye[..., 2:]\n",
    "    img_size = np.array([image_w, image_h], dtype=pts_eye.dtype)\n",
    "    # Given our convention, we need to shift one pixel before dividing by 2.\n",
    "    cx_cy = (img_size - 1) / 2\n",
    "    fx_fy = cx_cy / np.absolute(pts_ndc).max()\n",
    "\n",
    "    # Some sanity checks\n",
    "    if np.any(pts_eye[..., 2:] < 0.0001) or np.any(fx_fy < min_focal):\n",
    "        raise ValueError(\"Unable to create crop camera\", fx_fy)\n",
    "\n",
    "    return fx_fy, cx_cy\n",
    "\n",
    "\n",
    "def gen_crop_parameters_from_points(\n",
    "    camera_orig: CameraModel,\n",
    "    pts_world,\n",
    "    new_image_size: Tuple[int, int],\n",
    "    mirror_img_x: bool,\n",
    "    camera_angle: float = 0,\n",
    "    focal_multiplier: float = 0.95,\n",
    ") -> PinholePlaneCameraModel:\n",
    "    \"\"\"\n",
    "    Given the original camera transform and a list of 3D points in the world space,\n",
    "    compute the new perspective camera that makes sure after projection all the points\n",
    "    can be projected inside the image.\n",
    "\n",
    "    Auguments:\n",
    "    * camera_orig: the original camera used for generating an image. The returned camera\n",
    "        will have the same position but different rotation and intrinsics parameters.\n",
    "    * pts_world: points in the world space that must be projected inside the image by\n",
    "        the generated world to eye transform and intrinsics.\n",
    "    * new_image_size: target image size\n",
    "    * mirror_img_x: whether to flip the image. A typical use case is we usually mirror the\n",
    "        right hand images so that a model need to handle left hand data only\n",
    "    * camera_angle: how the camera is oriented physically so that we can rotate the object of\n",
    "        interest to the 'upright' direction\n",
    "    * focal_multiplier: when less than 1, we are zooming out a little. The effect on the image\n",
    "        is some margin will be left at the boundary.\n",
    "    \"\"\"\n",
    "    orig_world_to_eye_xf = np.linalg.inv(camera_orig.camera_to_world_xf)\n",
    "\n",
    "    crop_center = (pts_world.min(axis=0) + pts_world.max(axis=0)) / 2.0\n",
    "    new_world_to_eye = make_look_at_matrix(\n",
    "        orig_world_to_eye_xf, crop_center, camera_angle\n",
    "    )\n",
    "    if mirror_img_x:\n",
    "        mirrorx = np.eye(4, dtype=np.float32)\n",
    "        mirrorx[0, 0] = -1\n",
    "        new_world_to_eye = mirrorx @ new_world_to_eye\n",
    "\n",
    "    fx_fy, cx_cy = gen_intrinsics_from_bounding_pts(\n",
    "        transform3(new_world_to_eye, pts_world),\n",
    "        new_image_size[0],\n",
    "        new_image_size[1],\n",
    "    )\n",
    "    fx_fy = focal_multiplier * fx_fy\n",
    "\n",
    "    return PinholePlaneCameraModel(\n",
    "        width=new_image_size[0],\n",
    "        height=new_image_size[1],\n",
    "        f=fx_fy,\n",
    "        c=cx_cy,\n",
    "        distort_coeffs=[],\n",
    "        camera_to_world_xf=np.linalg.inv(new_world_to_eye),\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umetrack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
